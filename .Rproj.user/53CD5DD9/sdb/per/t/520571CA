{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Fundamentos de Estadistica\"\nauthor: \"Juan Carlos Martinez-Ovando\"\ndate: \"6 de abril de 2017\"\noutput:\n  rmdshower::shower_presentation:\n    self_contained: false\n    katex: true\n    ratio: 16x10\n    highlight: \"tango\"\n    css: /css/itam.css\n    keep_md: false\n---\n\n# Preliminares\n\n## \n\n> Would you tell me, please, which road do I take?\n>\n> That depends a good deal on where you want to get to.\n>\n> I don't much care where...\n>\n> Then it doesn't matter which way you go\n\n**Alicia en el país de las maravillas**\n\n## Presentaciones \n\nTomémonos unos minutos para decir lo siguiente:\n\n* ¿Nombre?\n* ¿A qué se dedican?\n* ¿En qué área están?\n* ¿Qué espero sacar del curso?\n\n## Hola, soy el curso \n\n[README](https://github.com/ITAM-DS/diplomado-bbva/blob/master/README.md)\n\n## Comunicación\n\nLista de correos:\n\n    `https://groups.google.com/forum/#!forum/diplomado-bbva-itam`\n\n\n# ¿Qué es?\n\n## La mayoría de las personas piensan que hago lo siguiente:\n\n```{r eval = FALSE}\ntarget <- Species ~ .\n\ntrain <- sample(nrow(iris), size = 100)\n\niris_train <- iris[train,]\niris_test <- iris[-train,]\n\ncdt <- ctree(target, iris_train)\n\ntable(predict(cdt, new_data=iris_test), iris_test$Species)\n                       \n             setosa versicolor virginica\n  setosa         15          0         0\n  versicolor      0         15         0\n  virginica       0          2        18\n```\n\n## \n\n<img src=\"images/ctree.png\" class=\"cover\">\n\n## \n\n<img src=\"images/done.jpg\" class=\"cover\">\n\n## En realidad ...\n\n> * La ciencia de datos, tiene que ver, con, bueno\n> * **DATOS**\n> * i.e. es fenomenológica, empírica\n\n\n## Varias definiciones \n\n> Data Science uses historical information to identify patterns or predict future events\n\n## Varias definiciones \n\n> Estadística operacionalizada*\n\n## Varias definiciones \n\n> La práctica de convertir datos crudos* (**raw**) *en información valiosa* (**valuable insights**) *que habiliten acciones informadas \n\n**Matt Gee (DSaPP)**\n\n\n## Mi definición \n\n> Estudio **fenomenológico** de **Sistemas Complejos Adaptativos**, con el propósito de\n> construir **productos de datos** que ayuden/soporten a la toma de decisiones y acciones\n> sobre el sistema.\n\n## Características\n\n1. No es una herramienta o técnica.\n2. La extracción de <span class=\"red2\">patrones o modelos útiles</span>  de una gran conjunto de datos.\n3. Patrones <span class=\"blue2\">No triviales</span>\n4. Patrones <span class=\"blue2\">Accionables</span>\n5. Sistemático `->` <span class=\"green2\">Proceso</span>.\n6. Algunas etapas del proceso tienen que ver con la aplicacon de la tecnología.\n7. Otras (muy importantes) con la creatividad del analista, conocimiento del negocio y sentido común.\n\n## ¿Para qué?\n\n* Toma de Decisiones Racionales\n    * i.e. tomar la mejor decisión basada en la evidencia (datos) disponible.\n* Aumento de Inteligencia (AI)\n    * *Human in the loop*: Plantea el problema, usa datos\n* Aplicar método científico a la toma de decisiones\n    * Se ha intentado desde los 40s, al parecer ahora si está teniendo impacto\n\n## ¿Por qué ahora?\n\n* Cómputo barato\n    * Almacenamiento\n    * RAM\n    * CPU\n    \n## En el gran esquema de las cosas\n\n> We wanted flying cars, \n> instead we got 140 characters\n\n** Peter Thiel **\n\n## En el gran esquema de las cosas\n\n> * Machine Learning → Artificial Narrow Intelligence   \n> * Data Science          → Intelligence Augmentation     \n> * Singularidad           → Artificial General Intelligence  \n\n\n# Relaciones\n\n## Antes de empezar\n\n* Ciencia de datos **no** es *big data*\n    * Aunque la incluye\n    * *Big data* es un conjunto de técnicas y tecnología para tratar con datos\n    \n* Tampoco es *Aprendizaje de Máquina*\n    * Aunque la incluye\n    \n* Ni mucho menos *Inteligencia de Negocios*\n    * Aunque la incluye\n\n\n## Relaciones\n\n<div class=\"double\">\n<p class=\"double-flow\">\n> * <span class=\"green\">Estadística</span>: Verifica hipótesis.\n> * <span class=\"blue\">ML</span>: Algoritmo.\n> * <span class=\"red\">BI</span>: ¿Qué pasó?\n</p>\n<p class=\"double-flow\">\n> * Bases de datos / DWH\n> * <span class=\"blue2\">Genera</span> hipótesis.\n> * Todo el proceso, aplicaciones, modificar.\n> * ¿Por qué? ¿Qué pasará?\n</p>\n</div>\n\n# Actividad\n\n## Actividad\n\nIdentifica como resolver las siguientes preguntas y si son de DS o de sus relaciones.\n\n* ¿Cuáles son los clientes que dejan más ganancia?\n* ¿Hay una diferencia real entre el cliente que genera más ganancia y el cliente medio?\n* ¿Quiénes son estos clientes?¿Podemos generar un *profiling*?\n\n## Actividad \n\nIdentifica como resolver las siguientes preguntas y si son de DS o de sus relaciones.\n\n* ¿Qué clientes se convertirán en los clientes que dejan ganancia? \n* ¿Cuánta ganancia espero los siguientes años?\n* ¿Qué puedo hacer para acelerar el proceso de  esos clientes?\n\n\n# ¿Quién lo hace?\n\n## \n\n<img src=\"./images/Data_Science_VD.png\" class=\"cover\">\n\n<p>\nCrédito: Drew Conway\n</p>\n\n## \n\n<img src=\"./images/unicorns_eat_rainbows_by_tomperwomper.jpg\" class=\"cover\">\n\n\n## Científico de datos \n\n* En realidad es trabajo de equipo\n* Enfrentamos complejidad con complejidad \n    * Ley de Ashby\n\n\n\n\n## Preguntas \n\n* ¿Quién?\n    * ¿Quién es más probable que falle en sus siguientes pagos?\n* ¿Qué?\n    * ¿Qué costo se está prediciendo para adquirir nuevos clientes?\n* ¿Dónde?\n    * ¿Dónde hay que abrir la nueva tienda para maximizar ROI?\n\n## Preguntas\n\n* ¿Cuándo?\n    * ¿Cuándo nos abandonará un cliente?\n* ¿Por qué?\n    * ¿Por qué este conjunto se comporta así?\n  \n## Tareas\n* <span class=\"blue2\">Clasificación</span>\n    * ¿A qué clase pertenece un individuo?\n* <span class=\"blue3\">*Scoring*</span> \n    * Asignar una <span class=\"red\">probabilidad</span> de que pertenezca a esa clase.\n* <span class=\"blue2\">Regresión</span> \n    * ¿Qué valor tiene una variable numérica, dado el individuo?\n    \n## Tareas\n* <span class=\"blue\">Similitudes</span>\n    * <span class=\"red4\">Identificar</span> que individuos similares dados los datos que sabemos de ellos.\n* <span class=\"blue2\">Clustering</span>\n    * <span class=\"red\">Agrupar</span> individuos por sus similitudes.\n* <span class=\"blue3\">Agrupamiento por co-ocurrencia</span>\n    * Encontrar <span class=\"red4\">asociaciones</span> entre las entidades basado en las transacciones que las involucran.\n  \n\n## Tareas\n\n* <span class=\"blue2\">Perfilamiento</span> \n    * Caracterizar el comportamiento de un individuo, grupo o población.\n* <span class=\"blue\">*Link Prediction*</span>\n    * Predecir conexiones entre individuos.\n* <span class=\"blue3\">Reducción de datos / Generación / Transformación de variables</span>\n*  <span class=\"blue2\">Modelado causal</span>\n    * ¿Qué eventos <span class=\"red2\">influyen</span> a otros?\n\n## Tipos de tareas\n\n* Supervisada  \n    * Muy importante producir una definición de la variable <span class=\"red2\">objetivo</span>.\n* Sin supervisar\n* *Reinforcement Learning*\n\n\n\n# Metodología: CRISP-DM\n\n## CRISP-DM \n\n<img src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/CRISP-DM_Process_Diagram.png/479px-CRISP-DM_Process_Diagram.png\" class=\"cover\"/>\n\n## CRISP-DM\n\n[Cross Industry Standard Process for Data Mining](http://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining)\n\n## CRISP-DM: Business Understanding \n* En este paso, el científico de datos, busca entender las **razones** del proyecto de datos, desde la perspectiva del negocio\n* Los problemas <span class=\"red\">nunca</span> vienen presentados como un problema de ciencia de datos.\n* Replantear el problema, como problema de ciencia de datos es una de las cosas más importantes del CRISP-DM.\n\n## CRISP-DM: Data Understanding \n* El científico de datos debe de familiarizarse con los datos, sus potencialidades y sus limitaciones.\n* En este paso, el científico de datos empieza a formular **hipótesis**.\n* Las hipotésis deben de ser evaluadas / confirmadas con el área de negocio.\n* Entender la limitaciones (y fortalezas) de los datos es vital.\n* Rara vez los datos fueron tomados pensando en el problema.\n\n## CRISP-DM: Data Preparation \n* *Data selection*, *Integration*, *Transformation*, y *pre-processing* de los datos.\n    * a.k.a. *Data munging*, *data cleansing*\n* <span class=\"red\">80%</span> / <span class=\"blue\"> 20% </span>\n* Cuidado con los datos \"cruzados\"\n\n\n## Lo que no dice el CRISP-DM: 80/20\n\n* 80% es data cleansing...\n* 20% es quejarse del data cleansing\n\n## Lo que no dice el CRISP-DM: 80/20 Personas\n\n> talking to people, not talking to computers \n\n**Matt Gee (DSaPP)**\n\n\n## Lo que no dice el CRISP-DM: Retos técnicos\n\nLas imágenes que sigues son cortesía de *Ihab Ilyas* de **Tamr**\n\n## \n\n<img src=\"images/tamr_a.png\" class=\"cover\">\n\n## \n\n<img src=\"images/tamr_b.png\" class=\"cover\">\n\n## \n\n<img src=\"images/tamr_c.png\" class=\"cover\">\n\n## \n\n<img src=\"images/tamr_d.png\" class=\"cover\">\n\n## \n\n<img src=\"images/tamr_e.png\" class=\"cover\">\n\n## \n\n<img src=\"images/tamr_f.png\" class=\"cover\">\n\n\n## CRISP-DM: Modelado \n* Se aplican **algoritmos** a los datos con el objetivo de obtener *patrones*\n* Le dedicaremos muchas horas más adelante\n\n## CRISP-DM: Evaluación \n* Los *patrones* encontrados son evaluados, usando como métrica el hecho de que respondan al problema de negocio.\n* Si es necesario se puede regresar a *Business Understanding*.\n* Le dedicaremos muchas horas más adelante\n\n\n## CRISP-DM: Deployment \n* El conocimiento ganado son presentados y puestos en producción para resolver el problema de negocio.\n* ¿Cómo impactar?\n* ¿Cómo implementar?\n* ¿Cómo mantener funcionando?\n* <span class=\"green\"> El modelo no es lo que el científico de datos diseña, es lo que el ingeniero construye</span>.\n\n## Lo que no dice el CRISP-DM\n\n* Recolección de los datos\n* Almacenamiento de los datos\n* Análisis exxploratorio de los datos\n* Análisis gráfico exploratorio de los datos\n\n## Lo que no dice el CRISP-DM: Mantenimiento {.fullscreen}\n\n<img src=\"images/credit_ml.png\" class=\"cover\">\n\n## Lo que no dice el CRISP-DM: Mantenimiento \n\n> * Falta de barreras claras en la abstracción\n> * Cambios en alguna parte, cambia en todas partes\n> * El sistema no es estacionario (*Time drifting*)\n> * Falta de *feedback loops*\n> * Refuerzo de *feedback loops*\n> * Dependencias en la configuración\n> * Dependencias en los datos\n\n# Proyectos de Ciencia de Datos\n\n## ¿Qué es un buen proyecto?\n\n> * Un problema que se pueda resolver\n> * Un problema  que represente un reto\n> * Un importante problema que tenga impacto\n> * Un socio/cliente motivado, capaz y comprometido\n    > * Conocimiento de dominio/del negocio\n    > * Entendimiento de los recursos de datos\n    > * Comprometido a la implantación\n> * Datos **Apropiados**, **Relevantes**  y **Disponibles**\n\n## Ejemplo: Acciones y *Dashboards*\n\n* ¿Cómo será usado el *dashboard*?\n* ¿Por qué necesitas esta representación/imagen?\n* ¿Cuáles serán las acciones que podrás tomar con el *dashboard*?\n\n## \n<img src=\"./images/relevancia_suficiencia.png\" class=\"cover\">\n\n\n**Source: [DSaPP](http://dsapp.uchicago.edu/)**\n\n## Categorías de proyectos\n* Early warning & intervention \n* Efficient resource allocation & targeted action\n* Effective advocacy & fundraising\n* Data-driven policy recommendation & evaluation\n* Description\n* Prediction\n* Detection\n* Evaluation\n\n## Preguntas a tener en cuenta\n\n* How early is possible and useful?\n* Group or individual predictions?\n    * Definir la *semántica* / *businnes object* (Ver [**Archimate**](http://archimate.nl/))\n* Performance metrics?\n* Does detection even matter?\n    * Intermediate Predictions / Sequential decisions\n\n## Preguntas que tener en cuenta\n\n* Survival models\n* Which $x$ should do I prioritize?\n* How far down the list needs to go? \n    * En el caso de que el entregable sea una lista\n* How to estimate the performance on the wild?\n* How to validate the ranking?\n\n## Tener claro qué\n\nSea $V$ un evento de falla, $I$ sea un evento de inspección.\n\n> * $P(V)$ `<-` todos los datos\n> * $P(V|I)$ `<-` datos etiquetados\n> * $P(I)$ `<-` heurística\n\n\n## Formulación / Planteamiento del Problema\n\n> * ¿Cuál es el problema?\n    * Olvídate de DS, ML, Big Data, Hadoop, etc\n> * Identifica los \"*ahora*\":\n    * ¿Qué están haciendo ahora? \n    * ¿Qué datos tienen ahora?\n    \n## Formulación / Planteamiento del Problema\n    \n> * Identifica las metas\n> * Identifica las acciones que puedes tomar para alcanzar esas metas\n    * Divide las acciones es una lista de preguntas y subacciones más fina\n> * Identifica las fuentes de datos que necesitas y que tienes\n> * Identifica el análisis/modelado que se necesita hacer\n\n\n## Metas  \n\n> * ¿Por qué quieren el proyecto?¿Qué les falta? ¿Qué necesitan?\n> * ¿Qué hacen para resolver el problema ahora?¿Por qué no es suficiente?\n> * ¿Qué recursos existen?¿Tendrás acceso a expertos del dominio?\n> * ¿Cómo planean utilizar los resultados?¿Cómo harán el _deploy_? ¿Qué restricciones existen?\n> * ¿La meta es específica y medible?\n\n\n# Actividad\n\n## *Scoping* (10 min)\n\nEn esta actividad estableceremos el alcance (*scoping*) de un proyecto de analítica que\nla organización esté enfrentando\n\n## *Scoping* (20 min)\n\n* Identifica la(s) meta(s)\n* Acciones\n    * ¿Quién? Nombra que individuos estarían ejecutando las acciones\n    * ¿Qué? \n    * ¿Cómo? \n    * ¿Qué programas/acciones puedo ejecutar?\n    * ¿Qué haría diferente si tuviera más información sobre donde intervenir con mayor eficacia?\n\n* Fuentes de datos \n    * existentes (que se tengan)\n    * que se necesiten recolectar\n    * Relaciones para obtener esos datos\n* Modelos\n\n\n# Expectativas\n\n## Métricas: Académicas\n\n* <span class=\"blue\">Exactitud (_Accuracy_)</span>\n* <span class=\"blue2\">Recall</span>\n* <span class=\"blue3\">Precisión</span>\n* <span class=\"blue\"> False positive rate (FPR)</span>\n\n## Expectativas  \n\n* Establecer las expectativas es una parte <span class=\"red2\">crucial</span> al definir el proyecto y los criterios de éxito.\n* Entender lo que el modelo  <span class=\"blue2\">debe</span> hacer para tener un desempeño aceptable es importante.\n* Entender lo que el modelo <span class=\"green2\">puede</span> hacer con los datos disponibles también.\n\n## Expectativas: El mínimo  \n\n* El mínimo esperado se puede definir usando <span class=\"blue3\">el modelo nulo</span>.\n    * Se puede entender como el \"educated guess\".\n* Si ya hay un modelo o una solución, ese es el <span class=\"blue3\">modelo nulo</span>.\n* Si no lo hay, es el modelo más simple: \n    * adivinando la variable dependiente,   \n    * predecir siempre con la media,     \n    * prediciendo siempre una clase en particular,  etc.\n\n## Expectativas: El mínimo  \n\n* Cuando tengas un modelo debe de ser mejor que el modelo nulo.\n* Para saber si es verdaderamente mejor, es necesario correr una <span class=\"blue\">prueba de hipótesis</span>.\n\n## Expectativas: El máximo \n\n* Debes de saber, al principio del proyecto, que tienes los datos para cubrir con las metas planteadas.\n* La cantidad a determinar es la <span class=\"green\">Varianza Inexplicable (unexplained variance)</span>\n    * ¿Cuánto de la variación de tus datos de salida no puede ser explicado por tus variables de entrada?\n* El límite de exactitud (_accuracy_) debido a la _unexplained variance_ se conoce como <span class=\"blue\">Tasa de Bayes</span> (_Bayes rate_).\n\n# Data\n\n## Data \n\n> * ¿Los datos están disponibles?\n> * ¿Los datos me ayudarán a resolver el problema?\n> * ¿Son suficientes?\n> * ¿La calidad es buena?\n\n\n## Datos son transversales en esfuerzo...\n\n> * Captura de datos\n> * Relevancia y Suficiencia\n> * Formato de los datos\n> * Almacenamiento de los datos\n> * Calidad de los datos\n> * Integración\n> * Accesibilidad\n> * Documentación\n\n\n## \n\n<img src=\"./images/componentes_data_maturity_level.png\" class=\"cover\">\n\n<p>\n**Source: [Data Maturity Framework @ DSaPP](http://dsapp.uchicago.edu/)**\n</p>\n\n# Forma de los datos\n\n\n## Forma *deseable*  de los datos: Tidy data\n\n* Para mucho de los análisis queremos que los datos estén en formato *tidy*.\n    * Ver el artículo [**Tidy Data**](http://vita.had.co.nz/papers/tidy-data.pdf) de Hadley Wickham\n    * Pero hay ejemplos donde no queremos *tidy data* e.g. [**Non Tidy Data**](http://simplystatistics.org/2016/02/17/non-tidy-data/)\n    * O grafos (ver más adelante)\n\n\n## Forma *deseable*  de los datos: Tidy data\n\nEs decir:\n\n> 1. Cada *variable* una columna\n> 2. Cada *observación* un renglón\n> 3. Cada *valor* una celda\n\n\n## Tidy data\n<img src=\"http://r4ds.had.co.nz/images/tidy-1.png\" class=\"cover\">\n\n<p>\n*Fuente:* R for Data Science, Wickham and Grolemund, 2016\n</p>\n\n\n## Formatos *on the wild*\n\n<img src=\"./images/formatos_indeseables_1.png\" class=\"cover\">\n\n## Formatos *on the wild*\n\n<img src=\"./images/formatos_indeseables_2.png\" class=\"cover\">\n\n## Formatos *on the wild*\n\n<img src=\"./images/formatos_indeseables_3.png\" class=\"cover\">\n\n\n## Formatos *on the wild*\n\nOtros ejemplos:\n\n* Nombres de las columnas representan valores de los datos en lugar de nombres de variables\n* Una columna contiene varias variables en lugar de una variable\n* Una tabla contiene más de una unidad de observación\n* Las variables están contenidas en los renglones y columnas, en lugar de sólo columnas.\n* Los datos de una unidad observacional están dispersas en varios *data sets*\n\n\n# Actividad\n\n## Determinar la madurez (15 min)\n\n[Descarga el MS Excel](http://dsapp.uchicago.edu/learning/datamaturity/)\n\n\n# Productos de datos\n\n## Producto de datos\n\n* Debe de ser un sistema continuo\n    * Recuerda que es un **CAS**\n\n* Todas las partes: reentrenamiento, recalibración, adquisición, movimiento de datos, transformación, limpieza, etc.\n    * i.e. **el Proceso**\n\n## Procesos vitales\n\n* Regularmente existen varios pasos de procesamiento para preparar los datos.\n    * Extraer los datos (desde una carpeta, el internet, una base de datos) e importarlos al data lake.\n    * Validar los datos.\n    * Transformarlos a un formato más adecuado.\n    * Ejecutar agregaciones y generación de variables.\n\n* Y pasos para preparar el modelo\n    * Entrenar, validar y seleccionar modelos.\n    * Poner en producción el modelo seleccionado\n\n## ¿Cómo se ve un producto de datos?\n\n<img src = \"images/producto_datos.png\" class=\"cover\">\n\n## El proceso de modelar ...\n\n<img src = \"images/producto_datos_a.png\" class=\"cover\">\n\n## Lo que no queremos hacer ...\n\n<img src = \"images/producto_datos_b.png\" class=\"cover\">\n\n## El significado de un producto de datos\n\n<img src = \"images/producto_datos_c.png\" class=\"cover\">\n\n## No olvidar a los usuarios\n\n* Aquí empieza la multiplicación de los procesos de ciencia de datos\n    * Más procesos\n    * Más algoritmos\n    * Más pipelines\n* Recomendaciones basadas en comportamiento y/u otros usuarios.\n* Necesitamos ver qué hacen los usuarios\n\n## No olvidar a los usuarios\n\n* Es muy importante tener los *logs* funcionando en cuanto antes\n    * Servicio al cliente\n    * Aumenta la inteligencia interna\n        * Organizacional\n        * De la “máquina”\n* La captura de datos no es lo único, si se proveé de Flight simulators, se generan nuevos datos.\n\n## [A systems view of ML, *Josh Bloom*](http://youtu.be/i-1UmCYyzi4)\n\n<div class=\"double\">\n<p class=\"double-flow\">\nAl final el producto de datos\ntambién es un CAS ...\n</p>\n<p class=\"double-flow\">\n<img src=\"images/cas_a.png\" class=\"one-col-image\">\n</p>\n</div>\n\n## [A systems view of ML, *Josh Bloom*](http://youtu.be/i-1UmCYyzi4)\n\n<div class=\"double\">\n<p class=\"double-flow\">\nAl final el producto de datos\ntambién es un CAS ...\n</p>\n<p class=\"double-flow\">\n<img src=\"images/cas_b.png\" class=\"one-col-image\">\n</p>\n</div>\n\n\n## [A systems view of ML, *Josh Bloom*](http://youtu.be/i-1UmCYyzi4) \n\n<div class=\"double\">\n<p class=\"double-flow\">\nAl final el producto de datos\ntambién es un CAS ...\n</p>\n<p class=\"double-flow\">\n<img src=\"images/cas_c.png\" class=\"one-col-image\">\n</p>\n</div>\n\n## Producción: Problemas\n\n* Los modelos necesitan ser entreados, actualizados y desplegados sin mucho problema\n* La mayoría de los *feed* de los modelos no son controlados por ustedes\n* Varios tipos de modelos\n* Varios lenguajes son necesarios\n    * Como veremos en este diplomado\n\n## Producción: *Temporal drift*\n\n* Conforme pasa el tiempo, los datos cambian\n    * El mundo cambia con el tiempo, y así nuestro modelos sobre ese mundo\n    * *Hackeo* de los modelos (*adversarial domains*) son intencionales, pero ejemplos de esto\n* ¿Cómo identificamos que hubo *drift*? De tal manera que podemos actualizar los modelos\n    * Esto es un área activa de investigación\n* ¿Ideas?\n    * Modelos de ensamble con diferentes ventanas de tiempo de entrenamiento\n    * Reentrenamiento frecuente\n    * Comparación de modelos entrenamos con datos actuales contra datos históricos quizá permitan detectar *drift*\n    \n## Producción: Reproducibilidad\n\n* Todos los experimentos y los modelos productivos deben de ser reproducibles.\n    * Más difícil de lo que parece...\n    * Requiere código histórico, datos históricos, formatos originales, *feature extraction*, etc.\n    \n* Si hay *adversarial domains* hay que saber que no evolucionan todos iguales.\n\n\n## Producción: Gobernanza de Modelos\n\n* Ventanas de entrenamiento\n* Publicación de modelos\n    * ¿PMML? ¿Serialización? ¿Imágenes de Docker?\n* Selección de modelos\n\n\n\n# Algunos conceptos\n\n## Predictibilidad \n\n\n> Predictability, a quantity which is a measure\n> of the degree of <span class=\"blue3\">reproducibility</span> of the patterns and regularities within data.\n> Thus, by observing patterns and regularities in one data set, we wish to predict\n> what patterns and regularities will exist in another, *statistically similar data set*.\n> Predictability varies as a function of a problem’s “features” and “feature\n> values”, i.e., the predictor variables in a problem and their values. For instance,\n> one might find that income is a weak predictor of car ownership but a strong\n> predictor of luxury car ownership.\n\n**C. R. Stephens et al, 2001**\n\n## Es importante tomar en cuenta  qué...\n\n1. Multi perspectiva\n2. Ruidoso `->` Probabilidad\n3. Modificar\n4. CAS\n    * Conjunto de leyes, Sistema Financiero, Sistema Económico, Sociedad, Cambio Climático, etc.\n\n# Retos\n\n## Retos de la Ciencia de Datos\n\n* No ignorar la complejidad y no linealidad del fenómeno: No “desbloquear” negativamente\n* Uno de los principales retos de la ciencia de datos es tratar con la complejidad de los datos.\n* Desarrollar Productos de datos\n    * También es un CAS.\n    * Cuya optimización es multiobjetivo...\n    \n## ¿Por qué no había funcionado?\n\n> * Nos habíamos conformado con los pocos datos que podíamos obtener (medir) y basado en eso reducíamos la dimensionalidad a unos pocos indicadores\n> * No teníamos datos para hacer frente a la complejidad de la realidad, y jugábamos a la segura.\n> * Esta situación ya no es la actual\n\n# DESBLOQUEO\n\n## ¿Por que no funcionaría ahora?\n\n> * Pensar cartesianamente en un mundo no lineal, es  el mejor de los casos temerario, en el peor catastrófico.\n> * El cerebro humano piensa en causa/efecto lineal y coloca las causas fuera del sistema siempre que puede, ignorando las relaciones.\n> * No se pueden ignorar los ciclos de retroalimentación.\n> * Feedback/forward loops\n> * No se puede ignorar los delays en el sistema.\n\n## Ejemplos\n\n* Algunos juegos:\n    * Beer game\t\n    * El farol problem\n    * Fishbank game\n    * Friday Night at the ER\n\n* En todos ellos (a pesar de lo simples que son) el caos emerge, debido a que se ignoran las bucles de retroalimentación y los retrasos.\n\n# Incertidumbre\n\n## Orígenes (Reales)\n\n* Mecánica Cuántica\n* Relatividad General\n\n## Orígenes\n\n* *Missing data*\n    * Primero detectar el patrón de *missings*\n    * Imputación\n* Datos inconsistentes\n* *Outliers*\n\n## Orígenes\n\n* Integración de sistemas\n    * Diferentes *constraints*\n    * Creación de esqeumas a nivel empresarial\n    * Semántica\n    * Actualizaciones incrementales\n    * Escalabilidad\n\n## Orígenes\n\n* *Data cleansing*\n    * Remover o corregir datos cuestionables de tal manera que pueden ser usados\n    * *approximated duplicates*\n* Inconsistencia en la integración\n    * El integrador no controla la generación de datos\n\n## Investigación\n\nEstos temas son campos de investigación actual, ver *Getting Data Right* en particular los \ncapítulos 1, 3 y 4.\n\n\n**Referencia:**\nHeld, Jerry, Michael Stonebraker, Thomas H Davenport, \nIhab Ilyas, Michael L Brodie, Andy Palmer, and \nJames Markarian. 2016. *Getting Data Right*. O’Reilly Media Inc. \n\n## ML reflects our biases...\n\n<div class=\"double\">\n<p class=\"double-flow\">\n*Machine-learning systems often reflect biases in the real world. “Some systems struggle to recognize non-white people because they were trained on Internet images which are overwhelmingly white,” she explained. “The bias of the Internet reflects the bias of society.”*\n<span class=\"left\">**Vivienne Ming** in the WSJ</span>\n</p>\n<p class=\"double-flow\">\n<img src=\"./images/misclassification_reflects_our_biases.png\" class=\"one-col-image\">\n</p>\n</div>\n\n## Obtener etiquetas\n\n* Busca más (Quizá esten en otra parte de la empresa)\n* Encuentra una variable/etiqueta *proxy*\n* Establece un nuevo proceso\n* Codifica a mano\n* *Crowd source*\n* *Semi supervised learning*\n\n## \n\n> Gov, NGO and companies needs to budget for data collection even the data that is not related to the enforcement or compliance of the process\n\n## Reproducibilidad\n\n> * Debes de ser capaz (o cualquier otro) de repetir tu trabajo sin depender de resultados intermedios.\n> * Todo debe de estar comentado con como reproducirlo o con documentación de donde se obtuvo.\n> * Debes de poder defender tu trabajo\n> * Manten tus `scripts` bajo control de versiones\n\n## Reproducibilidad\n\nEn estos casos de estudio nos vamos a encontrar con nuestro primer tipo de \n*pipeline*, en este caso en particular, este *pipeline* **no** es para ejecutar\ngrandes volúmenes de datos o para ejecutar contínuamente, si no para poder\nreproducir el proceso de exploración y modelado de datos.\n\n\n# Ética\n\n##\n> A technology is neither radical\n> nor revolucionary unless benefits **everyone**\n\n**DJ Patil, CDS EUA**\n\n\n## Potencialidades\n* Ciencia de datos y sus tecnologías asociadas tienen un enorme potencial de impactar positivamente a la sociedad.\n* Esta capacidad sólo va a aumentar en el futuro:\n    * Dispositivos conectados todo el tiempo en la red\n    * Recolección de datos ubicua\n    * Almacenamiento barato\n    * Sensores\n    * Poder de computo\n    \n## Reto\n* El reto es no usar este poder para obtener consecuencias indeseables o discriminatorias.\n    * Si no se implantan con cuidado pueden perpetuar, exacerbar, o enmascar discrimincación\n\n## ¿La Ciencia de Datos es objetiva?\n\n* Regularmente se asume que las técnicas de Ciencia de datos no contienen *bias* debido a la cantiad de datos que se manejan.\n    * Esto no es garantía de nada\n* Los retos se pueden agrupar como sigue:\n    * Retos relacionados con los datos usados como entrada a los algoritmos\n    * Retos relacionados al funcionamiento interno del algoritmo\n\n## Retos relacionados con los datos usados como entrada a los algoritmos\n* Existe una decisión de usar ciertos *data sets* sobre otros, y esto puede llevar a resultados discriminatorios\n    * Datos seleccionados mal\n    * Datos incompletos, incorrectos, desactualizados\n    * *Selection bias*\n    * Perpetuación y promoción de *bias* históricos\n\n## Retos relacionados al funcionamiento interno del algoritmo\n\n* El proceso para generar  el algoritmo es deconocido para el consumidor, estudiante, candidato de trabajo, o el público en general\n    * Ya que sontratados como confidenciales o propietarios por aquellas organizaciones que los usan\n* Esta falta de transparencia significa que el individuo afectado tiene una habilidad limitada para aprender de las\n  razones por las cuales la decisión se tomó y buscar alguna corrección de los errores o *bias* de los que fue sujeto.\n\n## Retos relacionados al funcionamiento interno del algoritmo\n* Esto se puede traducir en que algunos individuos son enteramente excluidos de ciertas oportunidades.\n* Sin salvaguardas relacionadas a la transparencia, *accountability* y debido proceso, pueden aparecer las siguientes fallas:\n    * Servicios de recomendación o personalización que limitan en lugar de expandir las opciones de los usuarios\n    * Mecanismos de *matching* mal diseñados\n    * Sistemas de decisión que suponen que la correlación implica causación\n    * *Data sets* que carecen de información o que representan desproporcionadamente a ciertas poblaciones\n\n## Otros retos\n\n* Privacidad\n    * [*¿Sousveillance?*](https://en.wikipedia.org/wiki/Sousveillance)\n    * También [aquí](http://bollier.org/blog/sousveillance-response-surveillance) y [aquí](http://www.surveillance-and-society.org/articles1(3)/sousveillance.pdf)\n* Seguridad\n    \n## Actividad\n\n¿Qué procesos existen en la organización para evaluar la ética de los sistemas y/o procesos?\n¿Qué sistemas actuales tienen problemas éticos?\n¿Cuáles a futuro?\n¿Qué acciones se deben de tomar en cuenta?\n\n# ¿Preguntas?\n\n# Gracias\n",
    "created" : 1490777499571.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2095354679",
    "id" : "520571CA",
    "lastKnownWriteTime" : 1490777570,
    "last_content_update" : 1490777570122,
    "path" : "~/JCMO.Trabajo/Seminars,Visits&Talks/17-04.Cinvestav/17-04.Cinvestav/17-04.Cinvestav_Slides.Rmd",
    "project_path" : "17-04.Cinvestav_Slides.Rmd",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}